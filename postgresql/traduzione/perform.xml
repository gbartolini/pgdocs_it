<?xml version="1.0" encoding="UTF-8"?>
<!-- $PostgreSQL$ -->

 <chapter id="performance-tips">
  <title>Suggerimenti per migliorare le prestazioni</title>

  <indexterm zone="performance-tips">
   <primary>prestazioni</primary>
  </indexterm>

  <para>
Le prestazioni della query possono essere influenzate da molte cose. Alcune di queste possono
essere controllate dall'utente, mentre altre sono fondamentali per il disegno del 
sistema. Questo capitolo presenta alcuni consigli per capire e mettere a punto 
le prestazioni di <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="using-explain">
   <title>Usare <command>EXPLAIN</command></title>

   <indexterm zone="using-explain">
    <primary>EXPLAIN</primary>
   </indexterm>

   <indexterm zone="using-explain">
    <primary>piano della query</primary>
   </indexterm>

   <para>
<productname>PostgreSQL</productname> crea un <firstterm>piano di query</firstterm>
per ogni query che riceve. Scegliere il giusto piano che corrisponda alla struttura della query
e alle proprietà dei dati è fondamentale per avere buone prestazioni, per questo il sistema
include un complesso <firstterm>pianificatore</firstterm> che prova a scegliere piani buoni.
È possibile usare il comando <xref linkend="sql-explain"/>
per vedere che piano di query viene generato dal pianificatore per ogni query.
La lettura dei piani è un'arte che necessita una vasta spiegazione,  
questo libro non lo è; ma ecco alcune informazioni.
   </para>

   <para>
La struttura di un piano di query è un albero di <firstterm>nodi di piano</firstterm>.
I nodi al livello più basso dell'albero sono nodi di scanzione di tabella: essi restituiscono righe grezze
da una tabella. Ci sono diversi tipi di nodi di scansione per diversi metodi di accesso 
alla tabella: scansioni sequenziali, scansioni con indice, scansioni con indice bitmap.
Se la query richiede il join, l'aggregazione, l'ordinamento o altre operazioni
sulle righe grezze, allora ci saranno nodi aggiuntivi superiori ai nodi di scansione
per eseguire queste operazioni. Di nuovo,
di solito c'è più di un modo possibile per fare queste operazioni,
così anche qui possono essere usati diversi tipi di nodo. L'output di 
<command>EXPLAIN</command> ha una linea per ogni nodo nell'albero del piano,
che mostra il tipo di base del nodo più il costo stimato che il pianificatore
ha calcolato per l'esecuzione di quel nodo. La prima linea (il nodo superiore a tutti gli altri)
possiede il costo totale stimato per l'esecuzione del piano; il pianificatore 
cerca di minimizzare questo numero.
   </para>

   <para>
Ecco un banale esempio, solo per mostrare come appare l'output: 
    <footnote>
     <para>
Gli esempi in questa sezione sono presi dal database di test di regressione
dopo aver fatto un <command>VACUUM ANALYZE</command>, usando i sorgenti di sviluppo della versione 8.2.
Si dovrebbe essere capaci di ottenere risultati simili se si provano gli esempi,
ma i costi stimati e i conteggi delle righe potrebbero variare sensibilmente
dato che le statistiche di <command>ANALYZE</command> sono campioni casuali piuttosto che esatte.
     </para>
    </footnote>

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>
   </para>

   <para>
I numeri presentati da <command>EXPLAIN</command> sono (da sinistra a destra):

    <itemizedlist>
     <listitem>
      <para>
Il costo stimato per iniziare (tempo speso prima che la scanzione di output possa partire,
per es., il tempo per fare l'ordinamento in un nodo di ordinamento)
      </para>
     </listitem>

     <listitem>
      <para>
Costo totale stimato (se vengono recuperate tutte le righe, sebbene potrebbero non esserlo;
per es., una query con una clausola <literal>LIMIT</literal> si fermerà prima 
di pagare il costo totale del nodo <literal>Limit</literal> di input del piano)
      </para>
     </listitem>

     <listitem>
      <para>
Numero stimato di righe in output da questo nodo del piano (di nuovo, solo 
se eseguito fino al completamento)
      </para>
     </listitem>

     <listitem>
      <para>
Dimensione media stimata (in byte) delle righe in output da questo nodo del piano
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
I costi sono misurati in unità arbitrarie determinate dai parametri di costo del
pianificatore (si veda <xref linkend="runtime-config-query-constants"/>).
La prassi tradizionale è di misurare i costi in unità di pagina disco;
così, <xref linkend="guc-seq-page-cost"/> è impostato convenzionalmente
a <literal>1.0</literal> e i parametri degli altri costi sono impostati relavitamente a quello.
(Gli esempi in questa sezione sono eseguiti con i parametri di costo predefiniti).
   </para>

   <para>
È importatnte notare che il costo di un nodo di livello superiore include 
il costo di tutti i suoi nodi figli. È importante anche capire che il costo 
tiene conto solo di cose di cui il pianificatore tiene di conto.
In particolare, il costo non considera il tempo speso trasmettendo le righe risultanti 
al client, che potrebbe essere un fattore importante
nel calcolo del reale tempo di esecuzione; ma il pianificatore lo ignora dato che non può  
cambiarlo modificando il piano. (Ogni piano corretto fornirà in output lo stesso insieme di righe).
   </para>

   <para>
Il valore delle <literal>righe</literal> è un po' complicato 
dato che <emphasis>non</emphasis> è il numero di righe processate 
o scansionate dal nodo del piano. Di solito è meno, 
in quanto riflette la selettività stimata di qualsiasi condizione <literal>WHERE</literal> applicata
al nodo. 
Idealmente le righe stimate si avvicineranno al numero di righe effettivamente restituite,  
aggiornate, o cancellate dalla query.
   </para>

   <para>
Ritornando ai nostri esempi:

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>
   </para>

   <para>
Questo è semplice come appare. Se si fa:

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';
</programlisting>

si scoprirà che <classname>tenk1</classname> ha 358 pagine di disco
e 10000 righe. Il costo stimato è calcolato come (pagine disco lette * 
<xref linkend="guc-seq-page-cost"/>) + (righe scansionate *
<xref linkend="guc-cpu-tuple-cost"/>). In maniera predefinita,
<varname>seq_page_cost</varname> è 1.0 e <varname>cpu_tuple_cost</varname> è 0.01,
così il costo stimato è (358 * 1.0) + (10000 * 0.01) = 458.
   </para>

   <para>
Adesso si modifichi la query originale per aggiungere una condizione <literal>WHERE</literal>:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7033 width=244)
   Filter: (unique1 &lt; 7000)
</programlisting>

Notare che l'output di <command>EXPLAIN</command> mostra che la clausola <literal>WHERE</literal>
è stata applicata come una condizione <quote>filtro</quote>; questo significa che 
il nodo del piano controlla la condizione per ogni riga che scansiona, e mostra in output solo
quelle che soddisfano la condizione.
La stima delle righe di output è stata ridotta a causa della clausola <literal>WHERE</literal>.
Comunque, la scansione dovrà comunque visitare tutte le 10000 righe, così il costo
non è diminuito; infatti si è alzato un po' (di 10000 * <xref
linkend="guc-cpu-operator-cost"/>, per essere esatti) per riflettere il tempo in più speso dalla CPU
per controllare la condizione  <literal>WHERE</literal>.
   </para>

   <para>
Il numero effettivo di righe che questa query selezionerà sono 7000, ma le  <literal>righe</literal>
stimate sono solo approssimate. Se si prova a duplicare questo esperimento,
probabilmente si otterranno stime leggermente diverse; in più, cambierà 
dopo ogni comando <command>ANALYZE</command>, dato che le statistiche 
prodotte da <command>ANALYZE</command> sono prese da un campione 
casuale della tabella.
   </para>

   <para>
Adesso, rendiamo la condizione più restrittiva:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=2.37..232.35 rows=106 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
         Index Cond: (unique1 &lt; 100)
</programlisting>

Qui il pianificatore ha deciso di usare un piano a due passaggi: il nodo del piano inferiore 
visita un indice per trovare le posizioni delle righe che corrispondono alla condizione 
dell'indice, e quindi il nodo di  piano superiore effettivamente ottiene le righe dalla tabella 
stessa. Prendere le righe separatamente è molto più costoso 
che leggerle sequenzialmente, ma dato che tutte le pagine  
della tabella devono essere visitate, è comunque più conveniente di una scansione
sequenziale. (La ragione per usare due livelli di piano è che il nodo del piano superiore 
ordina le posizioni della riga identificate dall'indice nell'ordine fisico
prima di leggerle, per minimizzare il costo di fetch separate.
Il <quote>bitmap</quote> menzionato nei nomi di nodo è il meccanismo che fa l'ordinamento).
   </para>

   <para>
Se la condizione <literal>WHERE</literal> è abbastanza selettiva, il pianificatore potrebbe
usare un <quote>simple</quote> piano di scansione di indice:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.00 rows=2 width=244)
   Index Cond: (unique1 &lt; 3)
</programlisting>

In questo caso le righe della tabella sono ottenute in ordine di indice, che le rende
ancora più costose da leggere, ma ce ne sono anche alcune per cui il costo aggiuntivo 
dell'ordinamento delle posizioni della riga non ha importanza. La maggior parte delle volte si vedrà 
questo tipo di piano per query che ottengono solo una singola riga, e per query
che hanno una condizione <literal>ORDER BY</literal> che corrisponde all'ordine dell'indice.
   </para>

   <para>
Aggiungere un'altra condizione alla clausola <literal>WHERE</literal>:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3 AND stringu1 = 'xxx';

                                  QUERY PLAN
------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.01 rows=1 width=244)
   Index Cond: (unique1 &lt; 3)
   Filter: (stringu1 = 'xxx'::name)
</programlisting>

La condizione <literal>stringu1 = 'xxx'</literal> aggiunta riduce la stima 
delle righe in output, ma non il costo, dato che si dovrà comunque visitare lo stesso
insieme di righe. Notare che la clausola <literal>stringu1</literal>
non può essere applicata come condizione di indice (dato che questo indice è solo sulla colonna
<literal>unique1</literal>). Invece viene applicato come filtro sulle righe 
ricavate dall'indice. Per questo il costo è aumentato sensibilmente 
per rispecchiare questo controllo ulteriore.
   </para>

   <para>
Se ci sono indici su diverse colonne referenziate nella <literal>WHERE</literal>, il pianificatore
potrebbe scegliere di usare una combinazione di AND o OR degli indici:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=11.27..49.11 rows=11 width=244)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=11.27..11.27 rows=11 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..8.65 rows=1042 width=0)
               Index Cond: (unique2 &gt; 9000)
</programlisting>

Ma questo richiede la visita di entrambi gli indici, che non è necessariamente un vantaggio  
rispetto ad usare solo un indice e trattare l'altra condizione come un filtro.
Se si cambiano gli intervalli coinvolti si noterà che il piano cambia conseguentemente.
   </para>

   <para>
Si provi a fare il join di due tabelle, usando le colonne di cui abbiamo discusso:

<programlisting>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</programlisting>
   </para>

   <para>
    In this nested-loop join, the outer (upper) scan is the same bitmap index scan we 
    saw earlier, and so its cost and row count are the same because we are
    applying the <literal>WHERE</literal> clause <literal>unique1 &lt; 100</literal>
    at that node.
    The <literal>t1.unique2 = t2.unique2</literal> clause is not relevant yet,
    so it doesn't affect the row count of the outer scan.  For the inner (lower) scan, the
    <literal>unique2</literal> value of the current outer-scan row is plugged into
    the inner index scan to produce an index condition like
    <literal>unique2 = <replaceable>constant</replaceable></literal>.
    So we get the same inner-scan plan and costs that we'd get from, say,
    <literal>EXPLAIN SELECT * FROM tenk2 WHERE unique2 = 42</literal>.  The
    costs of the loop node are then set on the basis of the cost of the outer
    scan, plus one repetition of the inner scan for each outer row (106 * 3.01,
    here), plus a little CPU time for join processing.
   </para>

   <para>
In questo esempio il conteggio della riga di output è lo stesso del prodotto 
dei conteggi delle due scansioni, ma questo non è vero in tutti i casi dato che
ci potrebbero essere clausole <literal>WHERE</literal> che fanno riferimento a entrambe le tabelle
e quindi possono essere applicate solo al punto join, non della scansione dell'input. 
Per esempio, se avessimo aggiunto
<literal>WHERE ... AND t1.hundred &lt; t2.hundred</literal>,
diminuirebbe il conteggio delle righe di output del nodo join, ma non cambierebbe 
la scansione dell'input.
   </para>

   <para>
Un modo di guardare ai diversi piani è di forzare il pianificatore a ignorare 
qualsiasi strategia pensi sia la più economica, usando i flag abilita/disabilita
descritti in <xref linkend="runtime-config-query-enable"/>.
(Queso è uno strumento rudimentale, ma utile. Si veda anche 
<xref linkend="explicit-joins"/>).


<programlisting>
SET enable_nestloop = off;
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=232.61..741.67 rows=106 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..458.00 rows=10000 width=244)
   -&gt;  Hash  (cost=232.35..232.35 rows=106 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
                     Index Cond: (unique1 &lt; 100)
</programlisting>

Questo piano propone di estrarre le 100 righe di interesse di <classname>tenk1</classname>
usando la stessa vecchia scansione di indice, mettendoli via in una tabella hash in memoria,
e quindi facendo una scansione sequenziale di <classname>tenk2</classname>, 
per possibili corrispondenze di <literal>t1.unique2 = t2.unique2</literal> per ogni riga di <classname>tenk2</classname>.
Il costo di leggere <classname>tenk1</classname> e impostare la tabella hash è un costo di inizio
per la join hash, dato che non ci sarà output finchè non è possibile 
cominciare a leggere  <classname>tenk2</classname>. Il tempo totale stimato per la join include anche
un costo massiccio per la CPU per sondare la tabella hash 10000 volte. 
Notare, comunque, che <emphasis>non</emphasis> si conterà 10000 volte  232.35;
la messa a punto della tabella hash viene fatta solo una volta in questo tipo di piano.
   </para>

   <para>
È possibile controllare l'accuratezza dei costi stimati del pianificatore
usando <command>EXPLAIN ANALYZE</command>.  Questo comando esegue effettivamente la query,
e quindi mostra il tempo di esecuzione reale accumulato all'interno di ogni nodo del piano
così come i costi stimati mostrati da  una normale <command>EXPLAIN</command>.
Per esempio, si potrebbe ottenere un risultato simile a questo:

<screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                                            QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488) (actual time=1.392..12.700 rows=100 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244) (actual time=0.878..2.367 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0) (actual time=0.546..0.546 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244) (actual time=0.067..0.078 rows=1 loops=100)
         Index Cond: (unique2 = t1.unique2)
 Total runtime: 14.452 ms
</screen>

Notare che i valori di <quote>actual time</quote> sono in millisecondi, 
mentre i <literal>costi</literal> stimati sono espressi in 
unità arbitrarie; così probabilmente non corrisponderanno.
La cosa da tener conto è se il rapporto tra il tempo effettivo e i costi stimati sono
molto diversi.
   </para>

   <para>
In alcuni piani di query, è possibile che un nodo di sottopiano venga eseguito più di una
volta. Per esempio, la scansione di indice interna viene eseguita una volta per ogni riga esterna 
nel piano con ciclo annidato visto sopra. In questi casi, 
il valore <literal>loops</literal> riporta il numero totale
di esecuzioni del nodo, e il tempo effettivo e i valori delle righe mostrate sono medie per esecuzione. 
Viene fatto questo per rendere i numeri confrontabili con il modo in cui sono mostrati i costi stimati.
Moltiplicare per il valore <literal>loops</literal> per avere il tempo totale speso effettivamente
in quel nodo.
   </para>

   <para>
Il <literal>tempo di esecuzione totale</literal> mostrato in <command>EXPLAIN
ANALYZE</command> include l'avvio dell'esecutore e il tempo per la chiusura, così come
il tempo speso processando le righe risultanti. Non include il tempo per il parsing,
la riscrittura, o la pianificazione. Per una query <command>SELECT</command>, il tempo di esecuzione totale
normalmente sarà solo un po' più grande rispetto al tempo totale
riportato per il nodo del piano più alto. Per i comandi <command>INSERT</command>, 
<command>UPDATE</command>, e <command>DELETE</command>, il tempo totale di esecuzione potrebbe essere
considerevolmente grande, dato che include il tempo speso processando le righe risultanti.
Per questi comandi, il tempo per il nodo di piano superiore è essenzialmente il 
tempo speso localizzando le vecchie righe e/o calcolando 
le nuove, ma non include il tempo speso applicando i cambiamenti.
Anche il tempo speso attivando i trigger, se presenti, sta fuori del nodo di piano superiore,
e viene mostrato separatamente per ogni trigger.
   </para>

   <para>
Vale la pena notare che i risultati di <command>EXPLAIN</command> non devono essere estrapolati
in situazioni diverse da quella che si sta attualmente testando; per esempio,
non si possono prendere per buoni i risultati di una tabella di piccole dimensioni 
se applicati ad una di grandi dimensioni. Le stime di costo del pianificatore non sono lineari 
e quindi si potrebbe essere scelto un piano diverso per una tabella di dimensioni diverse.
Un esempio estremo è che su una tabella che occupa solo una pagina disco, quasi sempre
si otterrà un piano scan sequenziale sia che gli indici siano disponibili che non.
Il pianificatore si rende conto che dovrà fare una lettura di pagina disco in ogni caso 
per processare la tabella, e quindi non c'è vantaggio nello spendere 
letture di pagina aggiuntive per cercare un indice.
   </para>
  </sect1>

 <sect1 id="planner-stats">
  <title>Statistiche usate dal pianificatore</title>

  <indexterm zone="planner-stats">
   <primary>statistiche</primary>
   <secondary>del pianificatore</secondary>
  </indexterm>

  <para>
Come abbiamo visto nella sezione precedente, il pianificatore di query ha bisogno di stimare
il numero di righe recuperate da una query per prendere buone scelte 
di piani di query. Questa sezione fornisce un'occhiata veloce alle statistiche 
che il sistema usa per queste stime.
  </para>

  <para>
Un componente delle statistiche è il numero totale di voci in ogni tabella e 
indice, così come il numero di blocchi del disco occupati 
da ogni tabella e indice. Questa informazione è mantenuta nella tabella
<link linkend="catalog-pg-class"><structname>pg_class</structname></link>,
nelle colonne <structfield>reltuples</structfield> e
<structfield>relpages</structfield>. È possibile darci un'occhiata con
query simili a questa:

<screen>
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)
</screen>

Qui è possibile notare che <structname>tenk1</structname> contiene 10000
righe, con i suoi indici, ma gli indici sono (ovviamente) molto più
piccoli della tabella.
  </para>

  <para>
Per ragioni di efficienza, <structfield>reltuples</structfield>
e <structfield>relpages</structfield> non sono aggiornate al volo, 
e così di solito contengono valori non aggiornati. 
Essi sono aggiornati dai comandi <command>VACUUM</command>, <command>ANALYZE</command> e
alcuni comandi DDL come <command>CREATE INDEX</command>.  Un <command>ANALYZE</command>
a sè stante, che non fa parte di <command>VACUUM</command>,
genera un valore <structfield>reltuples</structfield> approssimato
dato che non legge ogni riga della tabella. Il pianificatore 
bilancierà i valori che trova in <structname>pg_class</structname>
per corrispondere alla dimensione fisica corrente della tabella, ottenendo così un'approssimazione
più precisa.
  </para>

  <indexterm>
   <primary>pg_statistic</primary>
  </indexterm>

  <para>
La maggior parte delle query ricava solo una frazione delle righe in una tabella, 
considerando che le clausole  <literal>WHERE</literal> restringono le righe da esaminare.
Il pianificatore perciò deve fare una stima della 
<firstterm>selettività</firstterm> delle clausole <literal>WHERE</literal>, cioè
la frazione di righe che corrisponde ad ogni condizione nella clausola
<literal>WHERE</literal>. Le informazioni usate per questo compito sono salvate
nel catalogo di sistema 
<link linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>
Le voci in <structname>pg_statistic</structname> sono aggiornate 
dai comandi <command>ANALYZE</command>  e <command>VACUUM
ANALYZE</command>, e sono sempre approssimate anche quando appena aggiornate.
  </para>

  <indexterm>
   <primary>pg_stats</primary>
  </indexterm>

  <para>
Invece di guardare direttamente in <structname>pg_statistic</structname>,
è preferibile guardare nella sua vista 
<link linkend="view-pg-stats"><structname>pg_stats</structname></link>
quando di esaminano le statistiche manualmente. <structname>pg_stats</structname>
è progettata per essere più facilmente leggibile. Inoltre,
<structname>pg_stats</structname> è leggibile da tutti, mentre 
<structname>pg_statistic</structname> è leggibile solo dal superutente.
(Questo previene che gli utenti senza privilegi ricavino informazioni sul contenuto 
delle tabelle degli altri utenti dalle statistiche. La vista 
<structname>pg_stats</structname> mostra solo 
le righe di tabelle che l'utente corrente può leggere).
Per esempio, si potrebbe fare:

<screen>
SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals          
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen>

Notare che due righe sono visualizzate per la stessa colonna, una corrispondente 
alla gerarchia di ereditarietà completa cominciando dalla tabella 
<literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>),
e l'altra includendo solo la tabella <literal>road</literal> stessa 
(<literal>inherited</literal>=<literal>f</literal>).
  </para>

  <para>
L'ammontare di informazioni salvate in <structname>pg_statistic</structname>
da <command>ANALYZE</command>, in particolare il massimo numero di voci negli array
<structfield>most_common_vals</structfield> e <structfield>histogram_bounds</structfield>
per ogni colonna, può essere impostato in base alla colonna usando il comando  
<command>ALTER TABLE SET STATISTICS</command>, o globalmente impostando 
la variabile di configurazione <xref linkend="guc-default-statistics-target"/>.
Il limite predefinito è attualmente di 100 voci. Incrementare il limite 
potrebbe permettere strime del pianificatore più accurate, in particolare per
colonne con distribuzione dei dati non omogenea, al prezzo di consumare maggiore 
spazio in <structname>pg_statistic</structname> e leggermente più tempo per calcolare le stime.
Al contrario, un limite più basso potrebbe essere sufficiente
per colonne con distribuzione dei dati più semplice.
  </para>

  <para>
Ulteriori dettagli sull'uso delle statistiche da parte del pianificatore possono essere trovati
in <xref linkend="planner-stats-details"/>.
  </para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Controllare il pianificatore con clausole <literal>JOIN</literal> esplicite</title>

  <indexterm zone="explicit-joins">
   <primary>join</primary>
   <secondary>controllare l'ordine</secondary>
  </indexterm>

  <para>
È possibile 
controllare il pianificatore di query fino ad un certo punto usando la sintassi 
esplicita  <literal>JOIN</literal>.
Per vedere come mai è importante, abbiamo bisogno di alcune informazioni di base.
  </para>

  <para>
In una join semplice, tipo:
<programlisting>
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
</programlisting>
il pianificatore è libero di fare il join per le tabelle specificate in qualsiasi ordine. Per 
esempio, potrebbe generare un piano di query che fa il join tra A e B, usando 
la condizione <literal>WHERE</literal><literal>a.id = b.id</literal>, e quindi 
fare il join di C con questa tabella, usando l'altra condizione <literal>WHERE</literal>.
O potrebbe fare il join di B con C e quindi fare il join del risultato con A.
O potrebbe fare il join di A con C e poi fare il join con B - ma questo sarebbe inefficiente,
dato che si dovrebbe calcolare l'intero prodotto Cartesiano tra A e C,
non ci sono condizioni applicabili nella clausola <literal>WHERE</literal>
che permettano l'ottimizzazione della join. (Tutte le join
nell'esecutore di <productname>PostgreSQL</productname> avvengono
tra 2 tabelle di input, così è necessario costruire il risultato nell'uno o l'altro di questi due modi).
Il punto è che queste diverse possibilità di join danno risultati 
semanticamente equivalenti ma potrebbero avere costi di esecuzione immensamente diversi. 
Inoltre, il pianificatore li esplorerà tutti provando a trovare il piano query più efficiente. 
  </para>

  <para>
Quando una query coinvolge solo due o tre tabelle, non ci sono molti ordini di join
di cui preoccuparsi. Ma il numero di possibili ordini di join cresce
esponenzialmente man mano che il numero di tabelle si espande. Sotto le dieci o più tabelle di input 
non è più pratico fare una ricerca completa di tutte le possibilità,
ed anche per sei o sette tabelle la pianificazione potrebbe richiedere un tempo fastidiosamente lungo.
Quando ci sono ttroppe tabelle di input, il pianificatore di <productname>PostgreSQL</productname> 
passerà da una ricerca completa a una ricerca <firstterm>genetica</firstterm> probabilistica
attraverso un numero limitato di possibilità. (La soglia di passaggio
è definita dal parametro <xref linkend="guc-geqo-threshold"/>).
La ricerca genetica impiega meno tempo, ma non troverà 
necessariamente il miglior piano possibile.
  </para>

  <para>
Quando la query coinvolge outer join, il pianificatore ha meno libertà
rispetto a normali  (inner) join. Per esempio, considerare:
<programlisting>
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
</programlisting>
Anche se le restrizioni di questa query sono simili, superficialmente, all'esempio precedente,
le semantiche sono diverse perchè una riga dev'essere
emessa per ogni riga di A che non ha una riga corrispondente nella join di A con C.
Inoltre il pianificatore non ha scelta per l'ordine delle join qui: deve fare il join
di B con C e quindi il join di A con quel risultato. Di conseguenza, questa query impiega 
meno tempo a pianificare della query precedente. In altri casi, il pianificatore
potrebbe stabilire che più di un ordine di join è sicuro.
Per esempio, dato:
<programlisting>
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
</programlisting>
è valido fare il join di A sia con B che con C prima. Attualmente, solo
<literal>FULL JOIN</literal> vincola completamente l'ordine di join. La maggior parte dei 
casi pratici che coinvolgono <literal>LEFT JOIN</literal> o <literal>RIGHT JOIN</literal>
per certi versi possono essere risistemati. 
  </para>

  <para>
La sintassi esplicita delle inner join (<literal>INNER JOIN</literal>, <literal>CROSS
JOIN</literal>, o <literal>JOIN</literal>) è semantimante lo stesso di elencare le relazioni 
di input nella <literal>FROM</literal>, così non vincola
l'ordine di join.
  </para>

  <para>
Anche se la maggior parte dei tipo di <literal>JOIN</literal> non vincola completamente
l'ordine di join, è possibile istruire il pianificatore di query di 
<productname>PostgreSQL</productname> a trattare tutte le clausole
<literal>JOIN</literal> comunque come vincolanti per l'ordine di join. 
Per esempio, queste tre query sono logicalmente equivalenti:
<programlisting>
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
</programlisting>
Ma se si dice al pianificatore di onorare l'ordine <literal>JOIN</literal>,
il secondo e il terzo prende meno tempo per pianificare rispetto al primo. Questo effetto
non varrà la pena quando si ha a che fare con solo tre tabelle, ma può essere un 
salvavita con molte tabelle.
  </para>

  <para>
Per forzare il pianificatore a seguire l'ordine di join predisposto escplicitamente dalle
<literal>JOIN</literal>,
impostare il parametro <xref linkend="guc-join-collapse-limit"/> a 1.
(Altri valori possibili sono discussi sotto).
  </para>

  <para>
Non si ha bisogno di vincolare completamente l'ordine della join per risparmiare 
tempo di ricerca, dato che è giusto usare gli operatori <literal>JOIN</literal>
all'interno di elementi di un elenco di una normale <literal>FROM</literal>. Per esempio, considerare:
<programlisting>
SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;
</programlisting>
Con  <varname>join_collapse_limit</varname> = 1, questo 
forza il pianificatore a fare il join di A con B prima di fare il join con altre tabelle, 
ma altrimenti non vincola le sue scelte. In questo esempio, il numero di 
possibili ordini di join viene ridotto di un fattore di 5.
  </para>

  <para>
Vincolare la ricerca del planner in questo modo è una tecnica utile 
sia per ridurre il tempo di pianificazione sia per direzionare il pianificatore verso 
un buon piano di query. Se il pianificatore sceglie un cattivo ordine di join in modo predefinito, 
è possibile costringerlo a scegliere un ordine migliore con la sintassi <literal>JOIN</literal> -
assumendo che si conosca un ordine migliore, ovviamente. Si raccomanda di sperimentare. 
  </para>

  <para>
Una questione correlata che influisce sul tempo di pianificazione è di  
collassare le sottoquery nelle loro query genitore. Per esempio, considerare:
<programlisting>
SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;
</programlisting>
Questa situazione potrebbe presentarsi dall'uso di una vista che contiene una join; 
la regola <literal>SELECT</literal> della vista sarà inserita al posto del riferimento alla vista,
generando una query molto simile a quella sopra. Normalmente, il pianificatore
proverà a collassare la sottoquery nella query genitore, generando:
<programlisting>
SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;
</programlisting>
Questo di solito risulta in un piano migliore rispetto a pianificare le sottoquery 
separatamente. (Per esempio, le condizioni <literal>WHERE</literal> esterne potrebbero essere tali che  
il join di X con A elimini prima molte righe di A, eliminando così il bisogno di 
formare l'intero output logico della sottoquery). Ma allo stesso tempo,
abbiamo incrementato il tempo di pianificazione; qui, abbiamo un problema di join a cinque vie che 
sostituisce due problemi di join a tre vie. Data la crescita esponenziale 
del numero di possibilità, questo fa molta differenza. Il pianificatore 
prova ad evitare di bloccarsi in enormi problemi di  ricerche join 
non collassando una sottoquery se risultassero più di <varname>from_collapse_limit</varname>
elementi <literal>FROM</literal> nella query genitore.
È possibile variare il tempo di pianificazione a dispetto della qualità del piano 
aggiustando questo parametro. 
  </para>

  <para>
<xref linkend="guc-from-collapse-limit"/> e <xref
linkend="guc-join-collapse-limit"/>
hanno nomi simili perchè fanno quasi la stessa cosa: una controlla
quando il pianificatore <quote>distruggerà</quote> le sottoquery, e l'altra controlla 
quando distruggerà le join esplicite. Tipicamente
si vorrà o impostare <varname>join_collapse_limit</varname> uguale a 
<varname>from_collapse_limit</varname> (così che le join esplicite e le sottoquery
si comportino similmente) o impostare <varname>join_collapse_limit</varname> a 1 (se di vuole
controllare l'ordine di join con join esplicite). Ma si potrebbe impostarli   
diversamente se si sta provando a mettere a punto il passaggio tra 
il tempo di pianificazione e il tempo di esecuzione.  
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Popolare un database</title>

  <para>
Si potrebbe voler inserire una grande quantità di dati quando si popola per la prima volta 
un database. Questa sezione contiene alcuni suggerimenti su come farlo 
nel modo più efficiente possibile.
  </para>

  <sect2 id="disable-autocommit">
   <title>Disabilitare l'autocommit</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>caricare dati in grandi quantità</secondary>
   </indexterm>

   <para>
Quando si usano molteplici <command>INSERT</command>, disabilitare l'autocommit e fare solo 
una commit alla fine. (In SQL, questo significa scrivere <command>BEGIN</command> all'inizio
e <command>COMMIT</command> alla fine. Alcune librerie client potrebbero
farlo alle vostre spalle, nel qual caso ci si deve assicurare che 
la libreria lo faccia quando si vuole che venga fatto). Se si consente che ogni 
inserimento sia fatto separatamente, 
<productname>PostgreSQL</productname> farà molto lavoro per ogni riga che viene aggiunta.
Un beneficio aggiuntivo di fare tutti gli inserimenti 
in una transazione è che se l'inserimento di una riga 
è fallito allora l'inserimento di tutte le righe inserite fino a quel punto 
sarà sottoposto a rollback, così non si rimarrà bloccati con dati caricati parzialmente.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Usare <command>COPY</command></title>

   <para>
Usare <xref linkend="sql-copy"/> per caricare
tutte le righe con un comando, invece di usare una serie di 
comandi <command>INSERT</command>. Il comando <command>COPY</command>
è ottimizzato per il caricaemento di grandi quantità di righe; è meno flessibile
di <command>INSERT</command>, ma provoca un overhead significativamente minore 
per caricamenti di grandi quantità di dati. Dato che <command>COPY</command>
è un singolo comando, non c'è bisogno di disabilitare l'autocommit se si usa 
questo metodo per popolare una tabella.
   </para>

   <para>
Se non si può usare <command>COPY</command>, potrebbe essere d'aiuto usare <xref
linkend="sql-prepare"/> per creare un'istruzione <command>INSERT</command> "preparata",
quindi usare <command>EXECUTE</command> tante volte quanto richiesto. Questo evita 
un po' dell'overhead di fare ripetutamente il parsing e la pianificazione dell'<command>INSERT</command>.
Le diverse interfaccie forniscono questa facilitazione in maniere differenti;
si cerchi <quote>istruzioni preparate</quote> nella documentazione dell'interfaccia.
   </para>

   <para>
Notare che caricare un grande numero di righe usando 
<command>COPY</command> di solito è quasi sempre più veloce che usare 
<command>INSERT</command>, anche se viene usato <command>PREPARE</command> e 
inserimenti multipli sono racchiusi in una singola transazione.
   </para>

   <para>
<command>COPY</command> è più veloce quando usato all'interno della stessa transazione di un
precedente comando <command>CREATE TABLE</command> o <command>TRUNCATE</command>.
In tali casi non deve essere scritto nessun WAL,
dato che in caso di un errore, i file 
contenenti i dati nuovi caricati saranno comunque rimossi.
Comunque, questa considerazione si applica solo quando 
<xref linkend="guc-wal-level"/> è <literal>minimal</literal> altrimenti tutti i comandi
devono scrivere WAL.
   </para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Rimozione di indici</title>

   <para>
Se si sta caricando una tabella creata di recente, il metodo più veloce è di 
creare la tabella, caricare i dati della tabella usando 
<command>COPY</command>, quindi creare gli indici necessari per la tabella.
Creare un indice su dati pre-esistenti è più veloce di aggiornarli 
in modo incrementale quando ogni riga viene caricata.
   </para>

   <para>
Se si sta aggiungendo una grande quantità di dati a una tabella esistente,
potrebbe essere vantaggioso eliminare gli indici, 
caricare la tabella, e quindi ricreare gli indici. Ovviamente, le prestazioni
del database per altri utenti potrebbero soffrire durante 
il periodo che gli indici sono mancanti. Ci si dovrebbe pensare due volte prima di
eliminare un indice univoco, dato che i controlli di errore permessi dal
vincolo unique andranno persi mentre l'indice è mancante. 
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Rimozione di vincoli chiave esterna</title>

   <para>
Esattamente come con gli indici, un vincolo chiave esterna può essere controllato 
<quote>in grandi quantità</quote> più efficientemente riga per riga. Per questo potrebbe essere
utile eliminare vincoli chiave esterna, caricare dati, e ri-creare 
i vincoli. Di nuovo, c'è un bilanciamento tra la velocità di  caricamento dei dati  
e la perdita di controllo di errori mentre il vincolo è mancante. 
   </para>

   <para>
Oltretutto, quando si caricano dati all'interno di tabelle coni vincoli di chiave esterna,
ogni nuova  riga richiede una voce nell'elenco di trigger pendenti del server
(dato che è l'attivazione di un trigger che controlla 
il vincolo di chiave esterna della riga). Caricare molti milioni di righe può 
causare che la coda di eventi del trigger superi la memoria disponibile, portando a
uno swapping intollerabile o al fallimento totale del comando. Inoltre  
può essere <emphasis>necessario</emphasis>, non semplicemenete desiderabile, eliminare e ri-applicare
le chiavi esterne quando si caricano grandi quantità di dati. Se rimuovere temporaneamente 
il vincolo non è accettabile, l'unico altro modo può essere dividere 
l'operazione di caicamenti in transazioni più piccole.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Incrementare <varname>maintenance_work_mem</varname></title>

   <para>
Aumentare temporaneamente la variabile di configurazione <xref linkend="guc-maintenance-work-mem"/>
quando si caricano grandi quantità di dati può portare ad un aumento delle prestazioni.
Questo aiuterà a velocizzare i comandi <command>CREATE INDEX</command>
e <command>ALTER TABLE ADD FOREIGN KEY</command>.
Non farà molto per il comando <command>COPY</command> stesso, così questo consiglio 
è utile solo quando si sta usando una o entrambe delle tecniche viste sopra.
   </para>
  </sect2>

  <sect2 id="populate-checkpoint-segments">
   <title>Incrementare <varname>checkpoint_segments</varname></title>

   <para>
Anche incrementare temporaneamente la variabile di configurazione <xref
linkend="guc-checkpoint-segments"/> puù rendere più veloce il caricamento dei dati.
Questo perchè il caricamento di una grande quantità di dati 
in <productname>PostgreSQL</productname> causerà 
che si verifichino checkpoint più spesso della frequenza normale dei checkpoint
(specificata dalla variabile di configurazione <varname>checkpoint_timeout</varname>).
Ogni volta che avviene un checkpoint, tutte le pagine sporche devono essere
liberate su disco. Incrementando temporaneamente <varname>checkpoint_segments</varname>
durante un caricamento di grandi quantità di dati, il numero di checkpoint 
richiesti può essere ridotto.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Disabilitare l'archiviazione WAL e la replica streaming</title>

   <para>
Quando si caricano grandi quantità di dati all'interno di una installazione che usa
l'archiviazione WAL o la replica streaming, potrebbe essere più veloce prendere 
un nuovo backup di base dopoi che il caricamento è completato piuttosto che processare 
una grande quantità di dati WAL. Per prevenire i log WAL incrementali 
durante il caricamento, disabilitare l'archiviazione e la replica streaming, impostando
<xref linkend="guc-wal-level"/> a <literal>minimal</literal>,
<xref linkend="guc-archive-mode"/> a <literal>off</literal>, e
<xref linkend="guc-max-wal-senders"/> a zero.
Ma si noti che cambiare queste impostazioni richiede che il server venga riavviato.
   </para>

   <para>
    Aside from avoiding the time for the archiver or WAL sender to
    process the WAL data,
    doing this will actually make certain commands faster, because they
    are designed not to write WAL at all if <varname>wal_level</varname>
    is <literal>minimal</literal>.  
(Essi possono garantire sicurezza rispetto ai crash in maniera più conveniente
facendo un <function>fsync</function> alla fine invece che scrivere WAL).
Questo si applica ai seguenti comandi:
    <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CREATE INDEX</command> (e varianti tipo 
       <command>ALTER TABLE ADD PRIMARY KEY</command>)
      </para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>COPY FROM</command>, 
quando la tabella destinazione è stata creata o troncata precedentemente 
nella stessa transazione
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Eseguire <command>ANALYZE</command> dopo</title>

   <para>
Ogni volta che si è modificato significativamente la distribuzione dei dati
all'interno di una tabella, si raccomanda fortemente di eseguire <xref linkend="sql-analyze"/>.
Questo include il caricamento in massa di grandi quantità di dati nella tabella. Eseguire 
<command>ANALYZE</command> (o <command>VACUUM ANALYZE</command>)
assicute che il pianificatore abbia statistiche aggiornate sulla tabella.
Senza statistiche o con statistiche obsolete,  il pianificatore potrebbe
prendere decisioni sbagliate durante la pianificazione della query, generando cattive prestazioni
su qualsiasi tabella con statistiche inaccurate o non esistenti.
Notare che se il demone di autovacuum è attivo, potrebbe eseguire  
<command>ANALYZE</command> automaticamente; si veda 
<xref linkend="vacuum-for-statistics"/>
e <xref linkend="autovacuum"/> per maggiori informazioni.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Alcune note riguardo <application>pg_dump</application></title>

   <para>
Gli script di dump generati da <application>pg_dump</application> applicano automaticamente
diverse, ma non tutte, linee guida viste sopra. Per ricaricare un dump 
<application>pg_dump</application> il più velocemente possibile, si devono fare 
alcune cose aggiuntive manualmente. (Si noti che questi punti si applicano mentre  
si <emphasis>ripristina</emphasis> un dump, non mentre lo si <emphasis>crea</emphasis>.
Gli stessi punti si applicano sia che si carichi un dump testuale con   
<application>psql</application> sia usando <application>pg_restore</application> per caricare
da un file di archivio <application>pg_dump</application>).
   </para>

   <para>
In maniera predefinita, <application>pg_dump</application> usa <command>COPY</command>, e quando
sta generando un dump completo di schema e dati, è prudente caricari i dati prima
di creare gli indici e le chiavi esterne. Così, in questo caso
diverse linee guida sono gestite automaticamente. 
Quello che viene lasciato da fare all'utente è:
    <itemizedlist>
     <listitem>
      <para>
Impostare valori appropriati (per es., più grandi del normale) per
<varname>maintenance_work_mem</varname> e
<varname>checkpoint_segments</varname>.
      </para>
     </listitem>
     <listitem>
      <para>
Se si usa l'archiviazione WAL o le replica streaming, considerare di disabilitarle
durante il restore. Per fare ciò, impostare <varname>archive_mode</varname>
a <literal>off</literal>,
<varname>wal_level</varname> a <literal>minimal</literal> e
<varname>max_wal_senders</varname> a zero prima di caricare il dump.
Successivamente, rimetterli ai valori giusti e prendere un nuovo backup di base.
      </para>
     </listitem>
     <listitem>
      <para>
Considerare se l'intero dump debba essere ripristinato come singola transazione.
Per fare ciò, passare a <application>psql</application> o a <application>pg_restore</application>
l'opzione a riga di comando <option>-1</option> o
<option>--single-transaction</option>. Quando si utilizza questa modalità, 
il minimo errore provocherà il rollback dell'intero ripristino,    
eventualmente annullando diverse ore di elaborazione. Dipende da quanto sono 
collegati i dati il fatto che sia preferibile o meno eseguirer una pulizia manuale.
I comandi <command>COPY</command> saranno più veloci se si usa una singola transazione
e l'archiviazione WAL è disabilitata.
      </para>
     </listitem>
     <listitem>
      <para>
Se sul server database sono disponibili diverse CPU, considerare l'utilizzo dell'opzione
<option>--jobs</option> di <application>pg_restore</application>. Questo permette
il caricamento concorrente dei dati e la creazione concorrente di indici.
      </para>
     </listitem>
     <listitem>
      <para>
Successivamente lanciare <command>ANALYZE</command>.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
Anche un dump solamente dei dati utilizza <command>COPY</command>, ma non cancella o 
ricrea indici, e di solito non tocca le chiavi esterne.

     <footnote>
      <para>
Si può ottenere l'effetto di disabilitazione delle chiavi esterne usando l'opzione
<option>--disable-triggers</option> - ma si tenga presente che 
questo elimina, piuttosto che solamente postporre, la validazione delle chiavi esterne,
e così è possibile inserire dati sbagliati se la si usa.
      </para>
     </footnote>

Così quando si caricano dump di soli dati, è compito vostro cancellare e ricreare
gli indici e le chiavi esterne se si desidera usare quelle tecniche.
È comuqnue utile incrementare <varname>checkpoint_segments</varname>
mentre si caricano i dati, ma non preoccuparsi di incrementare
<varname>maintenance_work_mem</varname>; piuttosto, si potrebbe farlo successivamente mentre
si ricreano manualmente gli indici e le chiavi esterne.
E non dimenticarsi di lanciare <command>ANALYZE</command> quando si è fatto; si veda 
<xref linkend="vacuum-for-statistics"/>
e <xref linkend="autovacuum"/> per maggiori informazioni.
   </para>
  </sect2>
  </sect1>

  <sect1 id="non-durability">
   <title>Impostazioni non durevoli</title>

   <indexterm zone="non-durability">
    <primary>non-durevole</primary>
   </indexterm>

   <para>
La durabilità è una caratteristica del database che garantisce la registrazione di 
transazioni che hanno fatto il commit anche se il server ha un crash o perde
potenza. Comunque, la durevolezza aggiunge un overhead significativo al database, 
così se il sito non richiede tale garanzia, 
<productname>PostgreSQL</productname> può essere configurato per andare molto 
più veloce. I seguenti cambiamenti alla configurazione possono essere fatti
per aumentare le prestazioni in quei casi; essi non invalidano 
le garanzie di commit relative ai crash del database, 
solo per blocchi
bruschi del sistema, ad eccezione dei seguenti casi:

    <itemizedlist>
     <listitem>
      <para>
Posizionare la directory dei dati del cluster in un file system "memory-backed"
(per es. il disco <acronym>RAM</acronym>). Questo elimina tutto l'I/O del database,
ma limita i dati immagazzinati all'ammontare della memoria disponibile 
(e forse alla swap).
      </para>
     </listitem>

     <listitem>
      <para>
Disabilitare <xref linkend="guc-fsync"/>; non c'è necessità di fare un flush dei dati su disco.
      </para>
     </listitem>

     <listitem>
      <para>
Disabilitare <xref linkend="guc-full-page-writes"/>; non c'è bisogno di 
preoccuparsi di scritture di pagina parziali.    
      </para>
     </listitem>

     <listitem>
      <para>
Incrementare <xref linkend="guc-checkpoint-segments"/> e <xref
linkend="guc-checkpoint-timeout"/>; questo riduce la frequenza dei checkpoint,
ma incrementa i requisiti di immagazzinamento di  
<filename>/pg_xlog</filename>.
      </para>
     </listitem>

     <listitem>
      <para>
       Turn off <xref linkend="guc-synchronous-commit"/>;  there might be no
       need to write the <acronym>WAL</acronym> to disk on every
       commit.  This does affect database crash transaction durability.  
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect1>

 </chapter>
