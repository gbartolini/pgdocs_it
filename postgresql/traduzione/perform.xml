<?xml version="1.0" encoding="UTF-8"?>
<!-- $PostgreSQL$ -->

 <chapter id="performance-tips">
  <title>Suggerimenti per migliorare le prestazioni</title>

  <indexterm zone="performance-tips">
   <primary>prestazioni</primary>
  </indexterm>

  <para>
Le prestazioni della query possono essere influenzate da molte cose. Alcune di queste possono
essere controllate dall'utente, mentre altre sono fondamentali per il disegno del 
sistema. Questo capitolo presenta alcuni consigli per capire e mettere a punto 
le prestazioni di <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="using-explain">
   <title>Usare <command>EXPLAIN</command></title>

   <indexterm zone="using-explain">
    <primary>EXPLAIN</primary>
   </indexterm>

   <indexterm zone="using-explain">
    <primary>piano della query</primary>
   </indexterm>

   <para>
<productname>PostgreSQL</productname> crea un <firstterm>piano di query</firstterm>
per ogni query che riceve. Scegliere il giusto piano che corrisponda alla struttura della query
e alle proprietà dei dati è fondamentale per avere buone prestazioni, per questo il sistema
include un complesso <firstterm>pianificatore</firstterm> che prova a scegliere piani buoni.
È possibile usare il comando <xref linkend="sql-explain"/>
per vedere che piano di query viene generato dal pianificatore per ogni query.
La lettura dei piani è un'arte che necessita una vasta spiegazione,  
questo libro non lo è; ma ecco alcune informazioni.
   </para>

   <para>
La struttura di un piano di query è un albero di <firstterm>nodi di piano</firstterm>.
I nodi al livello più basso dell'albero sono nodi di scanzione di tabella: essi restituiscono righe grezze
da una tabella. Ci sono diversi tipi di nodi di scansione per diversi metodi di accesso 
alla tabella: scansioni sequenziali, scansioni con indice, scansioni con indice bitmap.
Se la query richiede il join, l'aggregazione, l'ordinamento o altre operazioni
sulle righe grezze, allora ci saranno nodi aggiuntivi superiori ai nodi di scansione
per eseguire queste operazioni. Di nuovo,
di solito c'è più di un modo possibile per fare queste operazioni,
così anche qui possono essere usati diversi tipi di nodo. L'output di 
<command>EXPLAIN</command> ha una linea per ogni nodo nell'albero del piano,
che mostra il tipo di base del nodo più il costo stimato che il pianificatore
ha calcolato per l'esecuzione di quel nodo. La prima linea (il nodo superiore a tutti gli altri)
possiede il costo totale stimato per l'esecuzione del piano; il pianificatore 
cerca di minimizzare questo numero.
   </para>

   <para>
Ecco un banale esempio, solo per mostrare come appare l'output: 
    <footnote>
     <para>
Gli esempi in questa sezione sono presi dal database di test di regressione
dopo aver fatto un <command>VACUUM ANALYZE</command>, usando i sorgenti di sviluppo della versione 8.2.
Si dovrebbe essere capaci di ottenere risultati simili se si provano gli esempi,
ma i costi stimati e i conteggi delle righe potrebbero variare sensibilmente
dato che le statistiche di <command>ANALYZE</command> sono campioni casuali piuttosto che esatte.
     </para>
    </footnote>

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>
   </para>

   <para>
I numeri presentati da <command>EXPLAIN</command> sono (da sinistra a destra):

    <itemizedlist>
     <listitem>
      <para>
Il costo stimato per iniziare (tempo speso prima che la scanzione di output possa partire,
per es., il tempo per fare l'ordinamento in un nodo di ordinamento)
      </para>
     </listitem>

     <listitem>
      <para>
Costo totale stimato (se vengono recuperate tutte le righe, sebbene potrebbero non esserlo;
per es., una query con una clausola <literal>LIMIT</literal> si fermerà prima 
di pagare il costo totale del nodo <literal>Limit</literal> di input del piano)
      </para>
     </listitem>

     <listitem>
      <para>
Numero stimato di righe in output da questo nodo del piano (di nuovo, solo 
se eseguito fino al completamento)
      </para>
     </listitem>

     <listitem>
      <para>
Dimensione media stimata (in byte) delle righe in output da questo nodo del piano
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
I costi sono misurati in unità arbitrarie determinate dai parametri di costo del
pianificatore (si veda <xref linkend="runtime-config-query-constants"/>).
La prassi tradizionale è di misurare i costi in unità di pagina disco;
così, <xref linkend="guc-seq-page-cost"/> è impostato convenzionalmente
a <literal>1.0</literal> e i parametri degli altri costi sono impostati relavitamente a quello.
(Gli esempi in questa sezione sono eseguiti con i parametri di costo predefiniti).
   </para>

   <para>
È importatnte notare che il costo di un nodo di livello superiore include 
il costo di tutti i suoi nodi figli. È importante anche capire che il costo 
tiene conto solo di cose di cui il pianificatore tiene di conto.
In particolare, il costo non considera il tempo speso trasmettendo le righe risultanti 
al client, che potrebbe essere un fattore importante
nel calcolo del reale tempo di esecuzione; ma il pianificatore lo ignora dato che non può  
cambiarlo modificando il piano. (Ogni piano corretto fornirà in output lo stesso insieme di righe).
   </para>

   <para>
Il valore delle <literal>righe</literal> è un po' complicato 
dato che <emphasis>non</emphasis> è il numero di righe processate 
o scansionate dal nodo del piano. Di solito è meno, 
in quanto riflette la selettività stimata di qualsiasi condizione <literal>WHERE</literal> applicata
al nodo. 
Idealmente le righe stimate si avvicineranno al numero di righe effettivamente restituite,  
aggiornate, o cancellate dalla query.
   </para>

   <para>
Ritornando ai nostri esempi:

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>
   </para>

   <para>
Questo è semplice come appare. Se si fa:

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';
</programlisting>

si scoprirà che <classname>tenk1</classname> ha 358 pagine di disco
e 10000 righe. Il costo stimato è calcolato come (pagine disco lette * 
<xref linkend="guc-seq-page-cost"/>) + (righe scansionate *
<xref linkend="guc-cpu-tuple-cost"/>). In maniera predefinita,
<varname>seq_page_cost</varname> è 1.0 e <varname>cpu_tuple_cost</varname> è 0.01,
così il costo stimato è (358 * 1.0) + (10000 * 0.01) = 458.
   </para>

   <para>
Adesso si modifichi la query originale per aggiungere una condizione <literal>WHERE</literal>:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7033 width=244)
   Filter: (unique1 &lt; 7000)
</programlisting>

Notare che l'output di <command>EXPLAIN</command> mostra che la clausola <literal>WHERE</literal>
è stata applicata come una condizione <quote>filtro</quote>; questo significa che 
il nodo del piano controlla la condizione per ogni riga che scansiona, e mostra in output solo
quelle che soddisfano la condizione.
La stima delle righe di output è stata ridotta a causa della clausola <literal>WHERE</literal>.
Comunque, la scansione dovrà comunque visitare tutte le 10000 righe, così il costo
non è diminuito; infatti si è alzato un po' (di 10000 * <xref
linkend="guc-cpu-operator-cost"/>, per essere esatti) per riflettere il tempo in più speso dalla CPU
per controllare la condizione  <literal>WHERE</literal>.
   </para>

   <para>
Il numero effettivo di righe che questa query selezionerà sono 7000, ma le  <literal>righe</literal>
stimate sono solo approssimate. Se si prova a duplicare questo esperimento,
probabilmente si otterranno stime leggermente diverse; in più, cambierà 
dopo ogni comando <command>ANALYZE</command>, dato che le statistiche 
prodotte da <command>ANALYZE</command> sono prese da un campione 
casuale della tabella.
   </para>

   <para>
Adesso, rendiamo la condizione più restrittiva:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=2.37..232.35 rows=106 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
         Index Cond: (unique1 &lt; 100)
</programlisting>

Qui il pianificatore ha deciso di usare un piano a due passaggi: il nodo del piano inferiore 
visita un indice per trovare le posizioni delle righe che corrispondono alla condizione 
dell'indice, e quindi il nodo di  piano superiore effettivamente ottiene le righe dalla tabella 
stessa. Prendere le righe separatamente è molto più costoso 
che leggerle sequenzialmente, ma dato che tutte le pagine  
della tabella devono essere visitate, è comunque più conveniente di una scansione
sequenziale. (La ragione per usare due livelli di piano è che il nodo del piano superiore 
ordina le posizioni della riga identificate dall'indice nell'ordine fisico
prima di leggerle, per minimizzare il costo di fetch separate.
Il <quote>bitmap</quote> menzionato nei nomi di nodo è il meccanismo che fa l'ordinamento).
   </para>

   <para>
Se la condizione <literal>WHERE</literal> è abbastanza selettiva, il pianificatore potrebbe
usare un <quote>simple</quote> piano di scansione di indice:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.00 rows=2 width=244)
   Index Cond: (unique1 &lt; 3)
</programlisting>

In questo caso le righe della tabella sono ottenute in ordine di indice, che le rende
ancora più costose da leggere, ma ce ne sono anche alcune per cui il costo aggiuntivo 
dell'ordinamento delle posizioni della riga non ha importanza. La maggior parte delle volte si vedrà 
questo tipo di piano per query che ottengono solo una singola riga, e per query
che hanno una condizione <literal>ORDER BY</literal> che corrisponde all'ordine dell'indice.
   </para>

   <para>
Aggiungere un'altra condizione alla clausola <literal>WHERE</literal>:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3 AND stringu1 = 'xxx';

                                  QUERY PLAN
------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.01 rows=1 width=244)
   Index Cond: (unique1 &lt; 3)
   Filter: (stringu1 = 'xxx'::name)
</programlisting>

La condizione <literal>stringu1 = 'xxx'</literal> aggiunta riduce la stima 
delle righe in output, ma non il costo, dato che si dovrà comunque visitare lo stesso
insieme di righe. Notare che la clausola <literal>stringu1</literal>
non può essere applicata come condizione di indice (dato che questo indice è solo sulla colonna
<literal>unique1</literal>). Invece viene applicato come filtro sulle righe 
ricavate dall'indice. Per questo il costo è aumentato sensibilmente 
per rispecchiare questo controllo ulteriore.
   </para>

   <para>
Se ci sono indici su diverse colonne referenziate nella <literal>WHERE</literal>, il pianificatore
potrebbe scegliere di usare una combinazione di AND o OR degli indici:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=11.27..49.11 rows=11 width=244)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=11.27..11.27 rows=11 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..8.65 rows=1042 width=0)
               Index Cond: (unique2 &gt; 9000)
</programlisting>

Ma questo richiede la visita di entrambi gli indici, che non è necessariamente un vantaggio  
rispetto ad usare solo un indice e trattare l'altra condizione come un filtro.
Se si cambiano gli intervalli coinvolti si noterà che il piano cambia conseguentemente.
   </para>

   <para>
Si provi a fare il join di due tabelle, usando le colonne di cui abbiamo discusso:

<programlisting>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</programlisting>
   </para>

   <para>
    In this nested-loop join, the outer (upper) scan is the same bitmap index scan we
    saw earlier, and so its cost and row count are the same because we are
    applying the <literal>WHERE</literal> clause <literal>unique1 &lt; 100</literal>
    at that node.
    The <literal>t1.unique2 = t2.unique2</literal> clause is not relevant yet,
    so it doesn't affect the row count of the outer scan.  For the inner (lower) scan, the
    <literal>unique2</literal> value of the current outer-scan row is plugged into
    the inner index scan to produce an index condition like
    <literal>unique2 = <replaceable>constant</replaceable></literal>.
    So we get the same inner-scan plan and costs that we'd get from, say,
    <literal>EXPLAIN SELECT * FROM tenk2 WHERE unique2 = 42</literal>.  The
    costs of the loop node are then set on the basis of the cost of the outer
    scan, plus one repetition of the inner scan for each outer row (106 * 3.01,
    here), plus a little CPU time for join processing.
   </para>

   <para>
    In this example the join's output row count is the same as the product
    of the two scans' row counts, but that's not true in all cases because
    you can have <literal>WHERE</literal> clauses that mention both tables
    and so can only be applied at the join point, not to either input scan.
    For example, if we added
    <literal>WHERE ... AND t1.hundred &lt; t2.hundred</literal>,
    that would decrease the output row count of the join node, but not change
    either input scan.
   </para>

   <para>
Un modo di guardare ai diversi piani è di forzare il pianificatore a ignorare 
qualsiasi strategia pensi sia la più economica, usando i flag abilita/disabilita
descritti in <xref linkend="runtime-config-query-enable"/>.
(Queso è uno strumento rudimentale, ma utile. Si veda anche 
<xref linkend="explicit-joins"/>).


<programlisting>
SET enable_nestloop = off;
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=232.61..741.67 rows=106 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..458.00 rows=10000 width=244)
   -&gt;  Hash  (cost=232.35..232.35 rows=106 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
                     Index Cond: (unique1 &lt; 100)
</programlisting>

Questo piano propone di estrarre le 100 righe di interesse di <classname>tenk1</classname>
usando la stessa vecchia scansione di indice, mettendoli via in una tabella hash in memoria,
e quindi facendo una scansione sequenziale di <classname>tenk2</classname>, 
per possibili corrispondenze di <literal>t1.unique2 = t2.unique2</literal> per ogni riga di <classname>tenk2</classname>.
Il costo di leggere <classname>tenk1</classname> e impostare la tabella hash è un costo di inizio
per la join hash, dato che non ci sarà output finchè non è possibile 
cominciare a leggere  <classname>tenk2</classname>. Il tempo totale stimato per la join include anche
un costo massiccio per la CPU per sondare la tabella hash 10000 volte. 
Notare, comunque, che <emphasis>non</emphasis> si conterà 10000 volte  232.35;
la messa a punto della tabella hash viene fatta solo una volta in questo tipo di piano.
   </para>

   <para>
È possibile controllare l'accuratezza dei costi stimati del pianificatore
usando <command>EXPLAIN ANALYZE</command>.  Questo comando esegue effettivamente la query,
e quindi mostra il tempo di esecuzione reale accumulato all'interno di ogni nodo del piano
così come i costi stimati mostrati da  una normale <command>EXPLAIN</command>.
Per esempio, si potrebbe ottenere un risultato simile a questo:

<screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                                            QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488) (actual time=1.392..12.700 rows=100 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244) (actual time=0.878..2.367 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0) (actual time=0.546..0.546 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244) (actual time=0.067..0.078 rows=1 loops=100)
         Index Cond: (unique2 = t1.unique2)
 Total runtime: 14.452 ms
</screen>

Notare che i valori di <quote>actual time</quote> sono in millisecondi, 
mentre i <literal>costi</literal> stimati sono espressi in 
unità arbitrarie; così probabilmente non corrisponderanno.
La cosa da tener conto è se il rapporto tra il tempo effettivo e i costi stimati sono
molto diversi.
   </para>

   <para>
In alcuni piani di query, è possibile che un nodo di sottopiano venga eseguito più di una
volta. Per esempio, la scansione di indice interna viene eseguita una volta per ogni riga esterna 
nel piano con ciclo annidato visto sopra. In questi casi, 
il valore <literal>loops</literal> riporta il numero totale
di esecuzioni del nodo, e il tempo effettivo e i valori delle righe mostrate sono medie per esecuzione. 
Viene fatto questo per rendere i numeri confrontabili con il modo in cui sono mostrati i costi stimati.
Moltiplicare per il valore <literal>loops</literal> per avere il tempo totale speso effettivamente
in quel nodo.
   </para>

   <para>
Il <literal>tempo di esecuzione totale</literal> mostrato in <command>EXPLAIN
ANALYZE</command> include l'avvio dell'esecutore e il tempo per la chiusura, così come
il tempo speso processando le righe risultanti. Non include il tempo per il parsing,
la riscrittura, o la pianificazione. Per una query <command>SELECT</command>, il tempo di esecuzione totale
normalmente sarà solo un po' più grande rispetto al tempo totale
riportato per il nodo del piano più alto. Per i comandi <command>INSERT</command>, 
<command>UPDATE</command>, e <command>DELETE</command>, il tempo totale di esecuzione potrebbe essere
considerevolmente grande, dato che include il tempo speso processando le righe risultanti.
Per questi comandi, il tempo per il nodo di piano superiore è essenzialmente il 
tempo speso localizzando le vecchie righe e/o calcolando 
le nuove, ma non include il tempo speso applicando i cambiamenti.
Anche il tempo speso attivando i trigger, se presenti, sta fuori del nodo di piano superiore,
e viene mostrato separatamente per ogni trigger.
   </para>

   <para>
    It is worth noting that <command>EXPLAIN</command> results should not be extrapolated
    to situations other than the one you are actually testing; for example,
    results on a toy-sized table cannot be assumed to apply to large tables.
    The planner's cost estimates are not linear and so it might choose
    a different plan for a larger or smaller table.  An extreme example
    is that on a table that only occupies one disk page, you'll nearly
    always get a sequential scan plan whether indexes are available or not.
    The planner realizes that it's going to take one disk page read to
    process the table in any case, so there's no value in expending additional
    page reads to look at an index.
   </para>
  </sect1>

 <sect1 id="planner-stats">
  <title>Statistics Used by the Planner</title>

  <indexterm zone="planner-stats">
   <primary>statistics</primary>
   <secondary>of the planner</secondary>
  </indexterm>

  <para>
Come abbiamo visto nella sezione precedente, il pianificatore di query ha bisogno di stimare
il numero di righe recuperate da una query per prendere buone scelte 
di piani di query. Questa sezione fornisce un'occhiata veloce alle statistiche 
che il sistema usa per queste stime.
  </para>

  <para>
   One component of the statistics is the total number of entries in
   each table and index, as well as the number of disk blocks occupied
   by each table and index.  This information is kept in the table
   <link linkend="catalog-pg-class"><structname>pg_class</structname></link>,
   in the columns <structfield>reltuples</structfield> and
   <structfield>relpages</structfield>.  We can look at it with
   queries similar to this one:

<screen>
SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)
</screen>

Qui è possibile notare che <structname>tenk1</structname> contiene 10000
righe, con i suoi indici, ma gli indici sono (ovviamente) molto più
piccoli della tabella.
  </para>

  <para>
Per ragioni di efficienza, <structfield>reltuples</structfield>
e <structfield>relpages</structfield> non sono aggiornate al volo, 
e così di solito contengono valori non aggiornati. 
Essi sono aggiornati dai comandi <command>VACUUM</command>, <command>ANALYZE</command> e
alcuni comandi DDL come <command>CREATE INDEX</command>.  Un <command>ANALYZE</command>
a sè stante, che non fa parte di <command>VACUUM</command>,
genera un valore <structfield>reltuples</structfield> approssimato
dato che non legge ogni riga della tabella. Il pianificatore 
bilancierà i valori che trova in <structname>pg_class</structname>
per corrispondere alla dimensione fisica corrente della tabella, ottenendo così un'approssimazione
più precisa.
  </para>

  <indexterm>
   <primary>pg_statistic</primary>
  </indexterm>

  <para>
La maggior parte delle query ricava solo una frazione delle righe in una tabella, 
considerando che le clausole  <literal>WHERE</literal> restringono le righe da esaminare.
Il pianificatore perciò deve fare una stima della 
<firstterm>selettività</firstterm> delle clausole <literal>WHERE</literal>, cioè
la frazione di righe che corrisponde ad ogni condizione nella clausola
<literal>WHERE</literal>. Le informazioni usate per questo compito sono salvate
nel catalogo di sistema 
<link linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>
Le voci in <structname>pg_statistic</structname> sono aggiornate 
dai comandi <command>ANALYZE</command>  e <command>VACUUM
ANALYZE</command>, e sono sempre approssimate anche quando appena aggiornate.
  </para>

  <indexterm>
   <primary>pg_stats</primary>
  </indexterm>

  <para>
Invece di guardare direttamente in <structname>pg_statistic</structname>,
è preferibile guardare nella sua vista 
<link linkend="view-pg-stats"><structname>pg_stats</structname></link>
quando di esaminano le statistiche manualmente. <structname>pg_stats</structname>
è progettata per essere più facilmente leggibile. Inoltre,
<structname>pg_stats</structname> è leggibile da tutti, mentre 
<structname>pg_statistic</structname> è leggibile solo dal superutente.
(Questo previene che gli utenti senza privilegi ricavino informazioni sul contenuto 
delle tabelle degli altri utenti dalle statistiche. La vista 
<structname>pg_stats</structname> mostra solo 
le righe di tabelle che l'utente corrente può leggere).
Per esempio, si potrebbe fare:

<screen>
SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals          
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen>

Notare che due righe sono visualizzate per la stessa colonna, una corrispondente 
alla gerarchia di ereditarietà completa cominciando dalla tabella 
<literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>),
e l'altra includendo solo la tabella <literal>road</literal> stessa 
(<literal>inherited</literal>=<literal>f</literal>).
  </para>

  <para>
L'ammontare di informazioni salvate in <structname>pg_statistic</structname>
da <command>ANALYZE</command>, in particolare il massimo numero di voci negli array
<structfield>most_common_vals</structfield> e <structfield>histogram_bounds</structfield>
per ogni colonna, può essere impostato in base alla colonna usando il comando  
<command>ALTER TABLE SET STATISTICS</command>, o globalmente impostando 
la variabile di configurazione <xref linkend="guc-default-statistics-target"/>.
Il limite predefinito è attualmente di 100 voci. Incrementare il limite 
potrebbe permettere strime del pianificatore più accurate, in particolare per
colonne con distribuzione dei dati non omogenea, al prezzo di consumare maggiore 
spazio in <structname>pg_statistic</structname> e leggermente più tempo per calcolare le stime.
Al contrario, un limite più basso potrebbe essere sufficiente
per colonne con distribuzione dei dati più semplice.
  </para>

  <para>
Ulteriori dettagli sull'uso delle statistiche da parte del pianificatore possono essere trovati
in <xref linkend="planner-stats-details"/>.
  </para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Controllare il pianificatore con clausole <literal>JOIN</literal> esplicite</title>

  <indexterm zone="explicit-joins">
   <primary>join</primary>
   <secondary>controllare l'ordine</secondary>
  </indexterm>

  <para>
È possibile 
controllare il pianificatore di query fino ad un certo punto usando la sintassi esplicita  <literal>JOIN</literal>.
Per vedere come mai è importante, abbiamo bisogno di alcune informazioni di base.
  </para>

  <para>
In una join semplice, tipo:
<programlisting>
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
</programlisting>
il pianificatore è libero di fare il join per le tabelle specificate in qualsiasi ordine. Per 
esempio, potrebbe generare un piano di query che fa il join tra A e B, usando 
la condizione <literal>WHERE</literal><literal>a.id = b.id</literal>, e quindi 
fare il join di C con questa tabella, usando l'altra condizione <literal>WHERE</literal>.
O potrebbe fare il join di B con C e quindi fare il join del risultato con A.
O potrebbe fare il join di A con C e poi fare il join con B - ma questo sarebbe inefficiente,
dato che si dovrebbe calcolare l'intero prodotto Cartesiano tra A e C,
non ci sono condizioni applicabili nella clausola <literal>WHERE</literal>
che permettano l'ottimizzazione della join. (Tutte le join
nell'esecutore di <productname>PostgreSQL</productname> avvengono
tra 2 tabelle di input, così è necessario costruire il risultato nell'uno o l'altro di questi due modi).
Il punto è che queste diverse possibilità di join danno risultati 
semanticamente equivalenti ma potrebbero avere costi di esecuzione immensamente diversi. 
Inoltre, il pianificatore li esplorerà tutti provando a trovare il piano query più efficiente. 
  </para>

  <para>
   When a query only involves two or three tables, there aren't many join
   orders to worry about.  But the number of possible join orders grows
   exponentially as the number of tables expands.  Beyond ten or so input
   tables it's no longer practical to do an exhaustive search of all the
   possibilities, and even for six or seven tables planning might take an
   annoyingly long time.  When there are too many input tables, the
   <productname>PostgreSQL</productname> planner will switch from exhaustive
   search to a <firstterm>genetic</firstterm> probabilistic search
   through a limited number of possibilities.  (The switch-over threshold is
   set by the <xref linkend="guc-geqo-threshold"/> run-time
   parameter.)
   The genetic search takes less time, but it won't
   necessarily find the best possible plan.
  </para>

  <para>
Quando la query coinvolge outer join, il pianificatore ha meno libertà
rispetto a normali  (inner) join. Per esempio, considerare:
<programlisting>
SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
</programlisting>
Anche se le restrizioni di questa query sono simili, superficialmente, all'esempio precedente,
le semantiche sono diverse perchè una riga dev'essere
emessa per ogni riga di A che non ha una riga corrispondente nella join di A con C.
Inoltre il pianificatore non ha scelta per l'ordine delle join qui: deve fare il join
di B con C e quindi il join di A con quel risultato. Di conseguenza, questa query impiega 
meno tempo a pianificare della query precedente. In altri casi, il pianificatore
potrebbe stabilire che più di un ordine di join è sicuro.
Per esempio, dato:
<programlisting>
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
</programlisting>
è valido fare il join di A sia con B che con C prima. Attualmente, solo
<literal>FULL JOIN</literal> vincola completamente l'ordine di join. La maggior parte dei 
casi pratici che coinvolgono <literal>LEFT JOIN</literal> o <literal>RIGHT JOIN</literal>
per certi versi possono essere risistemati. 
  </para>

  <para>
La sintassi esplicita delle inner join (<literal>INNER JOIN</literal>, <literal>CROSS
JOIN</literal>, o <literal>JOIN</literal>) è semantimante lo stesso di elencare le relazioni 
di input nella <literal>FROM</literal>, così non vincola
l'ordine di join.
  </para>

  <para>
Anche se la maggior parte dei tipo di <literal>JOIN</literal> non vincola completamente
l'ordine di join, è possibile istruire il pianificatore di query di 
<productname>PostgreSQL</productname> a trattare tutte le clausole
<literal>JOIN</literal> comunque come vincolanti per l'ordine di join. 
Per esempio, queste tre query sono logicalmente equivalenti:
<programlisting>
SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);
</programlisting>
Ma se si dice al pianificatore di onorare l'ordine <literal>JOIN</literal>,
il secondo e il terzo prende meno tempo per pianificare rispetto al primo. Questo effetto
non varrà la pena quando si ha a che fare con solo tre tabelle, ma può essere un 
salvavita con molte tabelle.
  </para>

  <para>
Per forzare il pianificatore a seguire l'ordine di join predisposto escplicitamente dalle
<literal>JOIN</literal>,
impostare il parametro <xref linkend="guc-join-collapse-limit"/> a 1.
(Altri valori possibili sono discussi sotto).
  </para>

  <para>
Non si ha bisogno di vincolare completamente l'ordine della join per risparmiare 
tempo di ricerca, dato che è giusto usare gli operatori <literal>JOIN</literal>
all'interno di elementi di un elenco di una normale <literal>FROM</literal>. Per esempio, considerare:
<programlisting>
SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;
</programlisting>
Con  <varname>join_collapse_limit</varname> = 1, questo 
forza il pianificatore a fare il join di A con B prima di fare il join con altre tabelle, 
ma altrimenti non vincola le sue scelte. In questo esempio, il numero di 
possibili ordini di join viene ridotto di un fattore di 5.
  </para>

  <para>
Vincolare la ricerca del planner in questo modo è una tecnica utile 
sia per ridurre il tempo di pianificazione sia per direzionare il pianificatore verso 
un buon piano di query. Se il pianificatore sceglie un cattivo ordine di join in modo predefinito, 
è possibile costringerlo a scegliere un ordine migliore con la sintassi <literal>JOIN</literal> -
assumendo che si conosca un ordine migliore, ovviamente. Si raccomanda di sperimentare. 
  </para>

  <para>
Una questione correlata che influisce sul tempo di pianificazione è di  
collassare le sottoquery nelle loro query genitore. Per esempio, considerare:
<programlisting>
SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE something) AS ss
WHERE somethingelse;
</programlisting>
Questa situazione potrebbe presentarsi dall'uso di una vista che contiene una join; 
la regola <literal>SELECT</literal> della vista sarà inserita al posto del riferimento alla vista,
generando una query molto simile a quella sopra. Normalmente, il pianificatore
proverà a collassare la sottoquery nella query genitore, generando:
<programlisting>
SELECT * FROM x, y, a, b, c WHERE something AND somethingelse;
</programlisting>
Questo di solito risulta in un piano migliore rispetto a pianificare le sottoquery 
separatamente. (Per esempio, le condizioni <literal>WHERE</literal> esterne potrebbero essere tali che  
il join di X con A elimini prima molte righe di A, eliminando così il bisogno di 
formare l'intero output logico della sottoquery). Ma allo stesso tempo,
abbiamo incrementato il tempo di pianificazione; qui, abbiamo un problema di join a cinque vie che 
sostituisce due problemi di join a tre vie. Data la crescita esponenziale 
del numero di possibilità, questo fa molta differenza. Il pianificatore 
prova ad evitare di bloccarsi in enormi problemi di  ricerche join 
non collassando una sottoquery se risultassero più di <varname>from_collapse_limit</varname>
elementi <literal>FROM</literal> nella query genitore.
È possibile variare il tempo di pianificazione a dispetto della qualità del piano 
aggiustando questo parametro. 
  </para>

  <para>
    <xref linkend="guc-from-collapse-limit"/> and <xref
    linkend="guc-join-collapse-limit"/>
   are similarly named because they do almost the same thing: one controls
   when the planner will <quote>flatten out</quote> subqueries, and the
   other controls when it will flatten out explicit joins.  Typically
   you would either set <varname>join_collapse_limit</varname> equal to
   <varname>from_collapse_limit</varname> (so that explicit joins and subqueries
   act similarly) or set <varname>join_collapse_limit</varname> to 1 (if you want
   to control join order with explicit joins).  But you might set them
   differently if you are trying to fine-tune the trade-off between planning
   time and run time.
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Popolare un database</title>

  <para>
Si potrebbe voler inserire una grande quantità di dati quando si popola per la prima volta 
un database. Questa sezione contiene alcuni suggerimenti su come farlo 
nel modo più efficiente possibile.
  </para>

  <sect2 id="disable-autocommit">
   <title>Disabilitare l'autocommit</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>caricare dati in grandi quantità</secondary>
   </indexterm>

   <para>
Quando si usano molteplici <command>INSERT</command>, disabilitare l'autocommit e fare solo 
una commit alla fine. (In SQL, questo significa scrivere <command>BEGIN</command> all'inizio
e <command>COMMIT</command> alla fine. Alcune librerie client potrebbero
farlo alle vostre spalle, nel qual caso ci si deve assicurare che 
la libreria lo faccia quando si vuole che venga fatto). Se si consente che ogni 
inserimento sia fatto separatamente, 
<productname>PostgreSQL</productname> farà molto lavoro per ogni riga che viene aggiunta.
Un beneficio aggiuntivo di fare tutti gli inserimenti 
in una transazione è che se l'inserimento di una riga 
è fallito allora l'inserimento di tutte le righe inserite fino a quel punto 
sarà sottoposto a rollback, così non si rimarrà bloccati con dati caricati parzialmente.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Use <command>COPY</command></title>

   <para>
    Use <xref linkend="sql-copy"/> to load
    all the rows in one command, instead of using a series of
    <command>INSERT</command> commands.  The <command>COPY</command>
    command is optimized for loading large numbers of rows; it is less
    flexible than <command>INSERT</command>, but incurs significantly
    less overhead for large data loads. Since <command>COPY</command>
    is a single command, there is no need to disable autocommit if you
    use this method to populate a table.
   </para>

   <para>
    If you cannot use <command>COPY</command>, it might help to use <xref
    linkend="sql-prepare"/> to create a
    prepared <command>INSERT</command> statement, and then use
    <command>EXECUTE</command> as many times as required.  This avoids
    some of the overhead of repeatedly parsing and planning
    <command>INSERT</command>. Different interfaces provide this facility
    in different ways; look for <quote>prepared statements</quote> in the interface
    documentation.
   </para>

   <para>
Notare che caricare un grande numero di righe usando 
<command>COPY</command> di solito è quasi sempre più veloce che usare 
<command>INSERT</command>, anche se viene usato <command>PREPARE</command> e 
inserimenti multipli sono racchiusi in una singola transazione.
   </para>

   <para>
<command>COPY</command> è più veloce quando usato all'interno della stessa transazione di un
precedente comando <command>CREATE TABLE</command> o <command>TRUNCATE</command>.
In tali casi non deve essere scritto nessun WAL,
dato che in caso di un errore, i file 
contenenti i dati nuovi caricati saranno comunque rimossi.
Comunque, questa considerazione si applica solo quando 
<xref linkend="guc-wal-level"/> è <literal>minimal</literal> altrimenti tutti i comandi
devono scrivere WAL.
   </para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Rimozione di indici</title>

   <para>
Se si sta caricando una tabella creata di recente, il metodo più veloce è di 
creare la tabella, caricare i dati della tabella usando 
<command>COPY</command>, quindi creare gli indici necessari per la tabella.
Creare un indice su dati pre-esistenti è più veloce di aggiornarli 
in modo incrementale quando ogni riga viene caricata.
   </para>

   <para>
Se si sta aggiungendo una grande quantità di dati a una tabella esistente,
potrebbe essere vantaggioso eliminare gli indici, 
caricare la tabella, e quindi ricreare gli indici. Ovviamente, le prestazioni
del database per altri utenti potrebbero soffrire durante 
il periodo che gli indici sono mancanti. Ci si dovrebbe pensare due volte prima di
eliminare un indice univoco, dato che i controlli di errore permessi dal
vincolo unique andranno persi mentre l'indice è mancante. 
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Rimozione di vincoli chiave esterna</title>

   <para>
Esattamente come con gli indici, un vincolo chiave esterna può essere controllato 
<quote>in grandi quantità</quote> più efficientemente riga per riga. Per questo potrebbe essere
utile eliminare vincoli chiave esterna, caricare dati, e ri-creare 
i vincoli. Di nuovo, c'è un bilanciamento tra la velocità di  caricamento dei dati  
e la perdita di controllo di errori mentre il vincolo è mancante. 
   </para>

   <para>
Oltretutto, quando si caricano dati all'interno di tabelle coni vincoli di chiave esterna,
ogni nuova  riga richiede una voce nell'elenco di trigger pendenti del server
(dato che è l'attivazione di un trigger che controlla 
il vincolo di chiave esterna della riga). Caricare molti milioni di righe può 
causare che la coda di eventi del trigger superi la memoria disponibile, portando a
uno swapping intollerabile o al fallimento totale del comando. Inoltre  
può essere <emphasis>necessario</emphasis>, non semplicemenete desiderabile, eliminare e ri-applicare
le chiavi esterne quando si caricano grandi quantità di dati. Se rimuovere temporaneamente 
il vincolo non è accettabile, l'unico altro modo può essere dividere 
l'operazione di caicamenti in transazioni più piccole.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Increase <varname>maintenance_work_mem</varname></title>

   <para>
    Temporarily increasing the <xref linkend="guc-maintenance-work-mem"/>
    configuration variable when loading large amounts of data can
    lead to improved performance.  This will help to speed up <command>CREATE
    INDEX</command> commands and <command>ALTER TABLE ADD FOREIGN KEY</command> commands.
    It won't do much for <command>COPY</command> itself, so this advice is
    only useful when you are using one or both of the above techniques.
   </para>
  </sect2>

  <sect2 id="populate-checkpoint-segments">
   <title>Increase <varname>checkpoint_segments</varname></title>

   <para>
    Temporarily increasing the <xref
    linkend="guc-checkpoint-segments"/> configuration variable can also
    make large data loads faster.  This is because loading a large
    amount of data into <productname>PostgreSQL</productname> will
    cause checkpoints to occur more often than the normal checkpoint
    frequency (specified by the <varname>checkpoint_timeout</varname>
    configuration variable). Whenever a checkpoint occurs, all dirty
    pages must be flushed to disk. By increasing
    <varname>checkpoint_segments</varname> temporarily during bulk
    data loads, the number of checkpoints that are required can be
    reduced.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Disable WAL archival and streaming replication</title>

   <para>
    When loading large amounts of data into an installation that uses
    WAL archiving or streaming replication, it might be faster to take a
    new base backup after the load has completed than to process a large
    amount of incremental WAL data.  To prevent incremental WAL logging
    while loading, disable archiving and streaming replication, by setting
    <xref linkend="guc-wal-level"/> to <literal>minimal</literal>,
    <xref linkend="guc-archive-mode"/> to <literal>off</literal>, and
    <xref linkend="guc-max-wal-senders"/> to zero.
    But note that changing these settings requires a server restart.
   </para>

   <para>
    Aside from avoiding the time for the archiver or WAL sender to
    process the WAL data,
    doing this will actually make certain commands faster, because they
    are designed not to write WAL at all if <varname>wal_level</varname>
    is <literal>minimal</literal>.  (They can guarantee crash safety more cheaply
    by doing an <function>fsync</function> at the end than by writing WAL.)
    This applies to the following commands:
    <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CREATE INDEX</command> (and variants such as
       <command>ALTER TABLE ADD PRIMARY KEY</command>)
      </para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>COPY FROM</command>, when the target table has been
       created or truncated earlier in the same transaction
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Run <command>ANALYZE</command> Afterwards</title>

   <para>
    Whenever you have significantly altered the distribution of data
    within a table, running <xref linkend="sql-analyze"/> is strongly recommended. This
    includes bulk loading large amounts of data into the table.  Running
    <command>ANALYZE</command> (or <command>VACUUM ANALYZE</command>)
    ensures that the planner has up-to-date statistics about the
    table.  With no statistics or obsolete statistics, the planner might
    make poor decisions during query planning, leading to poor
    performance on any tables with inaccurate or nonexistent
    statistics.  Note that if the autovacuum daemon is enabled, it might
    run <command>ANALYZE</command> automatically; see
    <xref linkend="vacuum-for-statistics"/>
    and <xref linkend="autovacuum"/> for more information.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Some Notes About <application>pg_dump</application></title>

   <para>
    Dump scripts generated by <application>pg_dump</application> automatically apply
    several, but not all, of the above guidelines.  To reload a
    <application>pg_dump</application> dump as quickly as possible, you need to
    do a few extra things manually.  (Note that these points apply while
    <emphasis>restoring</emphasis> a dump, not while <emphasis>creating</emphasis> it.
    The same points apply whether loading a text dump with
    <application>psql</application> or using <application>pg_restore</application> to load
    from a <application>pg_dump</application> archive file.)
   </para>

   <para>
    By default, <application>pg_dump</application> uses <command>COPY</command>, and when
    it is generating a complete schema-and-data dump, it is careful to
    load data before creating indexes and foreign keys.  So in this case
    several guidelines are handled automatically.  What is left
    for you to do is to:
    <itemizedlist>
     <listitem>
      <para>
       Set appropriate (i.e., larger than normal) values for
       <varname>maintenance_work_mem</varname> and
       <varname>checkpoint_segments</varname>.
      </para>
     </listitem>
     <listitem>
      <para>
       If using WAL archiving or streaming replication, consider disabling
       them during the restore. To do that, set <varname>archive_mode</varname>
       to <literal>off</literal>,
       <varname>wal_level</varname> to <literal>minimal</literal>, and
       <varname>max_wal_senders</varname> to zero before loading the dump.
       Afterwards, set them back to the right values and take a fresh
       base backup.
      </para>
     </listitem>
     <listitem>
      <para>
       Consider whether the whole dump should be restored as a single
       transaction.  To do that, pass the <option>-1</option> or
       <option>--single-transaction</option> command-line option to
       <application>psql</application> or <application>pg_restore</application>. When using this
       mode, even the smallest of errors will rollback the entire restore,
       possibly discarding many hours of processing.  Depending on how
       interrelated the data is, that might seem preferable to manual cleanup,
       or not.  <command>COPY</command> commands will run fastest if you use a single
       transaction and have WAL archiving turned off.
      </para>
     </listitem>
     <listitem>
      <para>
       If multiple CPUs are available in the database server, consider using
       <application>pg_restore</application>'s <option>--jobs</option> option.  This
       allows concurrent data loading and index creation.
      </para>
     </listitem>
     <listitem>
      <para>
       Run <command>ANALYZE</command> afterwards.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    A data-only dump will still use <command>COPY</command>, but it does not
    drop or recreate indexes, and it does not normally touch foreign
    keys.

     <footnote>
      <para>
       You can get the effect of disabling foreign keys by using
       the <option>--disable-triggers</option> option &mdash; but realize that
       that eliminates, rather than just postpones, foreign key
       validation, and so it is possible to insert bad data if you use it.
      </para>
     </footnote>

    So when loading a data-only dump, it is up to you to drop and recreate
    indexes and foreign keys if you wish to use those techniques.
    It's still useful to increase <varname>checkpoint_segments</varname>
    while loading the data, but don't bother increasing
    <varname>maintenance_work_mem</varname>; rather, you'd do that while
    manually recreating indexes and foreign keys afterwards.
    And don't forget to <command>ANALYZE</command> when you're done; see
    <xref linkend="vacuum-for-statistics"/>
    and <xref linkend="autovacuum"/> for more information.
   </para>
  </sect2>
  </sect1>

  <sect1 id="non-durability">
   <title>Non-Durable Settings</title>

   <indexterm zone="non-durability">
    <primary>non-durable</primary>
   </indexterm>

   <para>
    Durability is a database feature that guarantees the recording of
    committed transactions even if the server crashes or loses
    power.  However, durability adds significant database overhead,
    so if your site does not require such a guarantee,
    <productname>PostgreSQL</productname> can be configured to run
    much faster.  The following are configuration changes you can make
    to improve performance in such cases;  they do not invalidate
    commit guarantees related to database crashes, only abrupt operating
    system stoppage, except as mentioned below:

    <itemizedlist>
     <listitem>
      <para>
       Place the database cluster's data directory in a memory-backed
       file system (i.e. <acronym>RAM</acronym> disk).  This eliminates all
       database disk I/O, but limits data storage to the amount of
       available memory (and perhaps swap).
      </para>
     </listitem>

     <listitem>
      <para>
       Turn off <xref linkend="guc-fsync"/>;  there is no need to flush
       data to disk.
      </para>
     </listitem>

     <listitem>
      <para>
       Turn off <xref linkend="guc-full-page-writes"/>;  there is no need
       to guard against partial page writes.
      </para>
     </listitem>

     <listitem>
      <para>
       Increase <xref linkend="guc-checkpoint-segments"/> and <xref
       linkend="guc-checkpoint-timeout"/> ; this reduces the frequency
       of checkpoints, but increases the storage requirements of
       <filename>/pg_xlog</filename>.
      </para>
     </listitem>

     <listitem>
      <para>
       Turn off <xref linkend="guc-synchronous-commit"/>;  there might be no
       need to write the <acronym>WAL</acronym> to disk on every
       commit.  This does affect database crash transaction durability.
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect1>

 </chapter>
